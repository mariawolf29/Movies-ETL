{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_etl(wiki_data, kaggle_data, rating_data):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1 - Extract: Load data from files\n",
    "    try:\n",
    "        with open(wiki_data, mode='r') as file:\n",
    "            wiki_movies_raw = json.load(file)\n",
    "        print(len(wiki_movies_raw))\n",
    "\n",
    "        kaggle_metadata = pd.read_csv(kaggle_data, low_memory=False)\n",
    "        print(len(kaggle_metadata))\n",
    "\n",
    "        ratings = pd.read_csv(rating_data, nrows=10_000)\n",
    "        print(len(ratings))\n",
    "    except Exception as error:\n",
    "        print(f\"Error during loading files: {error}\")\n",
    "    \n",
    "    \n",
    "    # Step 2 - Transform\n",
    "    # TODO\n",
    "    # clean-up and transform data in movies_df and ratings\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame from the raw data.\n",
    "    wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
    "    \n",
    "    # Check if either “Director” or “Directed by” are keys in the current dict. If there is a director listed, we also want to check that the dict has an IMDb link\n",
    "    wiki_movies=[movie for movie in wiki_movies_raw\n",
    "             if ('Director' in movie or 'Directed by' in movie) \n",
    "                 and 'imdb_link' in movie]\n",
    "\n",
    "    # Make a DataFrame from wiki_movies\n",
    "    wiki_movies=pd.DataFrame(wiki_movies)\n",
    "    \n",
    "    # Eliminating TV shows ('No. of episodes'):\n",
    "    wiki_movies = [movie for movie in wiki_movies_raw\n",
    "               if ('Director' in movie or 'Directed by' in movie)\n",
    "                   and 'imdb_link' in movie\n",
    "                   and 'No. of episodes' not in movie]\n",
    "    \n",
    "    # Function to clean our movie data:\n",
    "    def clean_movie(movie):\n",
    "        movie = dict(movie) #create a non-destructive copy\n",
    "        alt_titles = {}\n",
    "        # combine alternate titles into one list\n",
    "        for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                    'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                    'Mandarin','McCune-Reischauer','Original title','Polish',\n",
    "                    'Revised Romanization','Romanized','Russian',\n",
    "                    'Simplified','Traditional','Yiddish']:\n",
    "            if key in movie:\n",
    "                alt_titles[key] = movie[key]\n",
    "                movie.pop(key)\n",
    "        if len(alt_titles) > 0:\n",
    "            movie['alt_titles'] = alt_titles\n",
    "\n",
    "        # merge column names\n",
    "        # merge column names\n",
    "        def change_column_name(old_name, new_name):\n",
    "            if old_name in movie:\n",
    "                movie[new_name] = movie.pop(old_name)\n",
    "                         \n",
    "        change_column_name('Adaptation by', 'Writer(s)')\n",
    "        change_column_name('Country of origin', 'Country')\n",
    "        change_column_name('Directed by', 'Director')\n",
    "        change_column_name('Distributed by', 'Distributor')\n",
    "        change_column_name('Edited by', 'Editor(s)')\n",
    "        change_column_name('Length', 'Running time')\n",
    "        change_column_name('Original release', 'Release date')\n",
    "        change_column_name('Music by', 'Composer(s)')\n",
    "        change_column_name('Produced by', 'Producer(s)')\n",
    "        change_column_name('Producer', 'Producer(s)')\n",
    "        change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "        change_column_name('Productioncompany ', 'Production company(s)')\n",
    "        change_column_name('Released', 'Release Date')\n",
    "        change_column_name('Release Date', 'Release date')\n",
    "        change_column_name('Screen story by', 'Writer(s)')\n",
    "        change_column_name('Screenplay by', 'Writer(s)')\n",
    "        change_column_name('Story by', 'Writer(s)')\n",
    "        change_column_name('Theme music composer', 'Composer(s)')\n",
    "        change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "        return movie\n",
    "    \n",
    "    # List of cleaned movies with a list comprehension\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "    \n",
    "    # Set wiki_movies_df to be the DataFrame created from clean_movies, and print out a list of the columns.\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "    \n",
    "    # Now we can rerun our list comprehension to clean wiki_movies and recreate wiki_movies_df.\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "    \n",
    "    # The code to extract the IMDb ID\n",
    "    wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "    \n",
    "    # drop any duplicates of IMDb IDs by using the drop_duplicates() method.\n",
    "    wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "    \n",
    "    # Remove Mostly Null Columns\n",
    "    # That will give us the columns that we want to keep, which we can select from our Pandas DataFrame as follows:\n",
    "    wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "    wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "    \n",
    "    #Convert and Parse the Data\n",
    "    # The box office data, which should give us code that we can reuse and tweak for the budget data since they’re both currency.\n",
    "\n",
    "    # First we’ll make a data series that drops missing values with the following:\n",
    "    box_office = wiki_movies_df['Box office'].dropna() \n",
    "\n",
    "    def is_not_a_string(x):\n",
    "        return type(x) != str\n",
    "\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    \n",
    "    # Form one “$123.4 million” (or billion)\n",
    "    form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
    "\n",
    "    # Form two “$123,456,789.”\n",
    "    form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "    \n",
    "    # Compare Values in Forms\n",
    "    matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE)\n",
    "    matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE)\n",
    "\n",
    "    # 1. Some values have spaces in between the dollar sign and the number.\n",
    "    orm_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
    "    form_two = r'\\$\\s*\\d{1,3}(?:,\\d{3})+'\n",
    "\n",
    "    # 2. Some values use a period as a thousands separator, not a comma.\n",
    "    form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'    \n",
    "  \n",
    "     # 3. Some values are given as a range.\n",
    "    box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)   \n",
    "    \n",
    "    # 4. “Million” is sometimes misspelled as “millon.”\n",
    "    form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'    \n",
    "     \n",
    "    # Extract and Convert the Box Office Values\n",
    "    matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE)\n",
    "    matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE)\n",
    "\n",
    "    # Extract and Convert the Box Office Values\n",
    "\n",
    "    def parse_dollars(s):\n",
    "        # if s is not a string, return NaN\n",
    "        if type(s) != str:\n",
    "            return np.nan\n",
    "\n",
    "        # if input is of the form $###.# million\n",
    "        if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "            # remove dollar sign and \" million\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "            # convert to float and multiply by a million\n",
    "            value = float(s) * 10**6\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # if input is of the form $###.# billion\n",
    "        elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "            # remove dollar sign and \" billion\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "            # convert to float and multiply by a billion\n",
    "            value = float(s) * 10**9\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # if input is of the form $###,###,###\n",
    "        elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "            # remove dollar sign and commas\n",
    "            s = re.sub('\\$|,','', s)\n",
    "\n",
    "            # convert to float\n",
    "            value = float(s)\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # otherwise, return NaN\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    # we need to extract the values from box_office using str.extract. Then we'll apply parse_dollars to the first column in the DataFrame returned by str.extract,\n",
    "    wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)   \n",
    "    \n",
    "    # We no longer need the Box Office column, so we’ll just drop it:\n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "\n",
    "    # Parse Budget Data\n",
    "\n",
    "    # Create a budget variable\n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "\n",
    "    # Convert any lists to strings:\n",
    "    budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "    # Then remove any values between a dollar sign and a hyphen (for budgets given in ranges):\n",
    "    budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "\n",
    "    # Patern matches\n",
    "    matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE)\n",
    "    matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove the citation references\n",
    "    budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "    \n",
    "    # Parse the budget values\n",
    "    wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    \n",
    "    # We can also drop the original Budget column\n",
    "    wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
    "\n",
    "    # Parse Release Date\n",
    "    release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    " \n",
    "    # parse those forms is with the following:\n",
    "    date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "    date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "    date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "    date_form_four = r'\\d{4}'\n",
    "\n",
    "    # use the built-in to_datetime() method in Pandas. Since there are different date formats, set the infer_datetime_format option to True.\n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)\n",
    "    \n",
    "     # Parse Running Time\n",
    "    running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)   \n",
    "    \n",
    "    # We only want to extract digits, and we want to allow for both possible patterns. Therefore, we’ll add capture groups around the \\d instances as well as add an alternating character. Our code will look like the following.\n",
    "    running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "    \n",
    "    # this new DataFrame is all strings, we’ll need to convert them to numeric values. Because we may have captured empty strings, we’ll use the to_numeric() method and set the errors argument to 'coerce'. Coercing the errors will turn the empty strings into Not a Number (NaN), then we can use fillna() to change all the NaNs to zeros.\n",
    "    running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "\n",
    "    # Now we can apply a function that will convert the hour capture groups and minute capture groups to minutes if the pure minutes capture group is zero, and save the output to wiki_movies_df:\n",
    "    wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "\n",
    "    # drop Running time from the dataset with the following code:\n",
    "    wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
    "\n",
    "    # Kaggle\n",
    "    # The following code will keep rows where the adult column is False, and then drop the adult column.\n",
    "    kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n",
    "\n",
    "     # Code creates the Boolean column we want. We just need to assign it back to video:\n",
    "    kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'   \n",
    "    \n",
    "     # Convert numeric columns:\n",
    "    try:\n",
    "        kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "        kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "        kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')   \n",
    "    except Exception as error:\n",
    "        print(f\"Error during numeric conversion: {error}\")\n",
    "     \n",
    "    # Convert to datetime:\n",
    "    try:\n",
    "        kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])   \n",
    "\n",
    "        ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s') \n",
    "    except Exception as error:\n",
    "        print(f\"Date time error: {error}\")\n",
    "\n",
    "    # Merge Wikipedia and Kaggle Metadata\n",
    "    movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "    \n",
    "     # Competing data:\n",
    "    # Wiki                     Movielens                Resolution\n",
    "    #--------------------------------------------------------------------------\n",
    "    # title_wiki               title_kaggle             Drop Wikipedia. \n",
    "    # running_time             runtime                  Keep Kaggle; fill in zeros with Wikipedia data.\n",
    "    # budget_wiki              budget_kaggle            Keep Kaggle; fill in zeros with Wikipedia data.\n",
    "    # box_office               revenue                  Keep Kaggle; fill in zeros with Wikipedia data.\n",
    "    # release_date_wiki        release_date_kaggle      Drop Wikipedia.\n",
    "    # Language                 original_language        Drop Wikipedia.\n",
    "    # Production company(s)    production_companies     Drop Wikipedia.  \n",
    "    \n",
    "    # Drop the title_wiki, release_date_wiki, Language, and Production company(s) columns.\n",
    "    movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "\n",
    "    # Function that fills in missing data for a column pair and then drops the redundant column.\n",
    "    def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "        df[kaggle_column] = df.apply(\n",
    "            lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "            , axis=1)\n",
    "        df.drop(columns=wiki_column, inplace=True)\n",
    "    \n",
    "    # Now we can run the function for the three column pairs that we decided to fill in zeros.\n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "\n",
    "    # Check that there aren’t any columns with only one value, since that doesn’t really provide any information. Don’t forget, we need to convert lists to tuples for value_counts() to work.\n",
    "    for col in movies_df.columns:\n",
    "        lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "        value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "        num_values = len(value_counts)\n",
    "        if num_values == 1:\n",
    "            print(col)\n",
    "        \n",
    "    movies_df['video'].value_counts(dropna=False)\n",
    "\n",
    "    # Reorder the columns:\n",
    "    movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                           'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                           'genres','original_language','overview','spoken_languages','Country',\n",
    "                           'production_companies','production_countries','Distributor',\n",
    "                           'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                          ]]\n",
    "\n",
    "    # Rename the columns to be consistent.\n",
    "    movies_df.rename({'id':'kaggle_id',\n",
    "                      'title_kaggle':'title',\n",
    "                      'url':'wikipedia_url',\n",
    "                      'budget_kaggle':'budget',\n",
    "                      'release_date_kaggle':'release_date',\n",
    "                      'Country':'country',\n",
    "                      'Distributor':'distributor',\n",
    "                      'Producer(s)':'producers',\n",
    "                      'Director':'director',\n",
    "                      'Starring':'starring',\n",
    "                      'Cinematography':'cinematography',\n",
    "                      'Editor(s)':'editors',\n",
    "                      'Writer(s)':'writers',\n",
    "                      'Composer(s)':'composers',\n",
    "                      'Based on':'based_on'\n",
    "                     }, axis='columns', inplace=True)\n",
    "    \n",
    "    # Transform and Merge Rating Data\n",
    "    # use a groupby on the “movieId” and “rating” columns and take the count for each group.\n",
    "    rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                    .rename({'userId':'count'}, axis=1) \\\n",
    "                    .pivot(index='movieId',columns='rating', values='count')\n",
    "\n",
    "    # Rename the columns so they’re easier to understand.\n",
    "    rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "\n",
    "    # Merge ratings with movie_df\n",
    "    movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "\n",
    "    # Fill missing values with NaN for missing ratings:\n",
    "    movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Step 3 - Load\n",
    "    # Store results in database\n",
    "    \n",
    "    try:\n",
    "        # pasword is stored in a config file\n",
    "        from config import db_password\n",
    "        \n",
    "        # For our local server, the connection string will be as follows:\n",
    "        db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/movie_data\"\n",
    "        \n",
    "        # Create database engine:\n",
    "        engine = create_engine(db_string)\n",
    "    except Exception as error:\n",
    "        print(f\"Error while connecting to database: {error}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        movies_df.to_sql(name='movies', con=engine, if_exists=\"replace\")\n",
    "        \n",
    "        ratings.to_sql(name='ratings', con=engine, if_exists=\"replace\")\n",
    "    except Exception as error:\n",
    "        print(f\"Error while saving data to database: {error}\")\n",
    "        return\n",
    "    \n",
    "    # print that the rows have finished importing\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '/Users/maruska/Documents/Bootcamp/Movies-ETL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7311\n",
      "45466\n",
      "10000\n",
      "video\n",
      "Done. 7.042062044143677 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "movie_etl(f'{file_dir}/wikipedia.movies.json',\n",
    "          f'{file_dir}/movies_metadata.csv',\n",
    "          f'{file_dir}/ratings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
